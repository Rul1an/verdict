# Verdict User Guide

**Verdict** is a strict, CI-first regression gate for RAG pipelines (and other LLM apps). It is designed to be deterministic, fast, and easy to integrate into Pull Request workflows.

## üöÄ Quickstart

1. **Install Verdict** (via `cargo` or pre-built binary):
   ```bash
   cargo install --git https://github.com/Rul1an/verdict.git verdict-cli
   ```

2. **Initialize Scaffolding**:
   Run `init` to generate a ready-to-use CI setup, including a sample config and traces for deterministic replay.
   ```bash
   verdict init --ci --gitignore
   ```
   This creates:
   - `ci-eval.yaml`: Evaluation configuration.
   - `traces/ci.jsonl`: Pre-recorded LLM interactions (Replay Mode).
   - `schemas/ci_answer.schema.json`: Example JSON Schema.
   - `.github/workflows/verdict.yml`: GitHub Actions workflow.

3. **Run CI Gate**:
   ```bash
   verdict ci --config ci-eval.yaml --trace-file traces/ci.jsonl --strict
   ```

---

## üí° Core Concepts

### Statuses
Verdict tests result in one of five statuses:
- **Pass**: Metric matched expectation.
- **Fail**: Metric failed (e.g. regex didn't match).
- **Error**: System error (e.g. LLM call failed, config error, trace missing).
- **Warn**: Test failed, but is marked as `warn` in Quarantine (Non-blocking by default).
- **Flaky**: Test passed sometimes and failed sometimes (Auto-rerun detected).

### Strict Mode (`--strict`)
By default, `Warn` and `Flaky` statuses are treated as passing (Exit Code 0).
Use `--strict` to treat them as failures (Exit Code 1), enforcing a clean green state.

### Replay Mode vs Reruns
- **Replay Mode**: When `--trace-file` is provided, Verdict uses recorded LLM responses. This allows for **deterministic** and **fast** CI runs without API costs.
- **Reruns**: In live mode, Verdict can retry failed tests (`--rerun-failures N`) to detect flakiness. In Replay Mode, reruns are forced to 0.

### Path Resolution
File paths in configuration (e.g., `schema_file`) are resolved **relative to the configuration file**. This ensures your config works consistently whether run from the project root or a subdirectory.

---

## üìù Configuration (`eval.yaml`)

```yaml
version: 1
suite: "my_rag_suite"
model: "gpt-4o" # or "trace" for replay
tests:
  - id: "rag_q1"
    input:
      prompt: "Explain RAG"
    expected:
      # Option A: Regex Match
      type: regex_match
      pattern: "retrieval.*generation"
      flags: ["i"]

  - id: "json_output"
    input:
      prompt: "Output JSON"
    expected:
      # Option B: JSON Schema
      type: json_schema
      schema_file: "schemas/answer.schema.json" # Relative to eval.yaml
```

### Metrics
- `must_contain`: List of substrings that must be present.
- `must_not_contain`: List of substrings that must be absent.
- `regex_match` / `regex_not_match`: Perl-style regex validation.
- `json_schema`: Validates structure against a JSON Schema (inline or file).

---

## üõ°Ô∏è Privacy & Security

### `--redact-prompts`
Use this flag to redact the `prompt` field in all generated artifacts (SARIF, JSON, JUnit). This prevents PII or sensitive data from leaking into CI logs.

```bash
verdict ci ... --redact-prompts
```

---

## üìä CI/CD Integration

Verdict is designed for GitHub Actions (and other CI systems).

### Reports
- `junit.xml`: Test results for CI UI integration. `Warn`/`Flaky` tests appear as "Passed" with warning logs (unless `--strict`).
- `sarif.json`: Static Analysis results for GitHub Code Scanning (showing failures inline in PRs).
- `run.json`: Full detailed JSON report.

### Workflow Example
See `.github/workflows/verdict.yml` generated by `verdict init --ci`.

---

## üîß Troubleshooting

- **"config error: failed to read schema_file"**: Verdict prints both the *resolved absolute path* and the *original relative path* to help you debug file location issues in CI.
- **"trace miss"**: In Replay Mode, this means the prompt requested is not found in the provided `--trace-file`.
