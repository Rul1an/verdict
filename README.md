<h1 align="center">
  <br>
  <img src="docs/assets/logo.svg" alt="Assay Logo" width="200">
  <br>
  Assay
  <br>
</h1>

<h4 align="center">Policy enforcement for AI agents</h4>

<p align="center">

  <a href="https://github.com/Rul1an/assay/actions/workflows/assay.yml">
    <img src="https://github.com/Rul1an/assay/actions/workflows/assay.yml/badge.svg" alt="Assay CI Gate">
  </a>
  <a href="https://crates.io/crates/assay">
    <img src="https://img.shields.io/crates/v/assay.svg" alt="Crates.io">
  </a>
  <a href="https://pypi.org/project/assay-it/">
    <img src="https://img.shields.io/pypi/v/assay-it.svg" alt="PyPI">
  </a>
  <a href="https://docs.assay.dev">
    <img src="https://img.shields.io/badge/docs-assay.dev-blue" alt="Docs">
  </a>
  <a href="LICENSE">
    <img src="https://img.shields.io/badge/license-MIT-green" alt="License">
  </a>
</p>

<p align="center">
  <a href="#quick-start">Quick Start</a> ‚Ä¢
  <a href="#why-assay">Why Assay</a> ‚Ä¢
  <a href="#how-it-works">How It Works</a> ‚Ä¢
  <a href="#documentation">Docs</a> ‚Ä¢
  <a href="#contributing">Contributing</a>
</p>

---

## The Problem

Your AI agent tests are **flaky**. OpenAI times out, the model hallucinates slightly differently, and your CI fails randomly. Developers stop trusting the pipeline.

Traditional test: `PR ‚Üí Call LLM ‚Üí Wait 3 min ‚Üí Random failure ‚Üí Retry ‚Üí üò§`

## The Solution

**Assay** records your agent's behavior once, then replays it locally ‚Äî **no API calls, no network, no flakiness**.

Assay test: `PR ‚Üí Replay trace ‚Üí 3ms ‚Üí Deterministic pass/fail ‚Üí ‚úÖ`

```bash
# Record once
assay import --format mcp-inspector session.json --init

# Test forever (0ms latency, $0 cost)
assay run --config mcp-eval.yaml --strict
```

---

## Quick Start

### Install

**Rust** (Recommended for CLI):
```bash
# Note: Crate is named 'assay-cli', binary is 'assay'
cargo install assay-cli --locked
```

**Python** (SDK):
```bash
pip install assay-it
```

### Run Your First Test

```bash
# 1. Import an MCP session (creates config automatically)
assay import --format mcp-inspector session.json --init

# 2. Run tests
assay run --config mcp-eval.yaml
```

Output:
```
Assay v0.8.0 ‚Äî Zero-Flake CI for AI Agents

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Test              ‚îÇ Status ‚îÇ Details                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ args_valid        ‚îÇ ‚úÖ PASS ‚îÇ 2ms                     ‚îÇ
‚îÇ sequence_valid    ‚îÇ ‚úÖ PASS ‚îÇ 1ms                     ‚îÇ
‚îÇ tool_blocklist    ‚îÇ ‚ùå FAIL ‚îÇ admin_delete called!    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Total: 3ms | 2 passed, 1 failed
```

### Add to CI

```yaml
# .github/workflows/agent-tests.yml
- uses: Rul1an/assay-action@v1
  with:
    config: mcp-eval.yaml
```

---

## Why Assay

|  | Traditional LLM Tests | Assay |
|--|----------------------|-------|
| **Speed** | 30s - 3min | **3ms** |
| **Cost** | $0.10 - $1.00/run | **$0.00** |
| **Flakiness** | 5-20% | **0%** |
| **Network** | Required | **None** |
| **Privacy** | Data sent to APIs | **Local only** |

### Use Cases

- **üîí Air-Gapped Enterprise** ‚Äî Banks, healthcare, defense. No data leaves your perimeter.
- **‚ö° High-Frequency CI** ‚Äî 20 PRs/day √ó 50 tests = $500/day with GPT-4. $0 with Assay.
- **üéØ MCP Native** ‚Äî Deep integration with Model Context Protocol. Test tool calls, not text.
- **ü§ñ Agent Self-Correction** ‚Äî Agents validate their own actions at runtime.

---

## How It Works

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. Record      ‚îÇ ‚îÄ‚îÄ‚ñ∫ ‚îÇ  2. Define      ‚îÇ ‚îÄ‚îÄ‚ñ∫ ‚îÇ  3. Replay      ‚îÇ
‚îÇ  Agent Session  ‚îÇ     ‚îÇ  Policies       ‚îÇ     ‚îÇ  & Validate     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                       ‚îÇ                       ‚îÇ
        ‚ñº                       ‚ñº                       ‚ñº
   session.json            mcp-eval.yaml           Pass/Fail
   (MCP Inspector)         (Your rules)            (Instant)
```

**Policies** define what "correct" means:

```yaml
# mcp-eval.yaml
tests:
  - id: discount_args
    metric: args_valid
    tool: apply_discount
    constraints:
      percent: { max: 30 }

  - id: read_before_write
    metric: sequence_valid
    rules:
      - type: before
        first: GetCustomer
        then: UpdateCustomer
```

---

## MCP Integration

Assay is built for the [Model Context Protocol](https://modelcontextprotocol.io).

### Import MCP Sessions

```bash
# From MCP Inspector
assay import --format mcp-inspector session.json

# Auto-generate policies from a "golden" session
assay import --format mcp-inspector good_run.json --init
```

### Assay as MCP Server

Let agents validate their own actions at runtime:

```bash
# Start Assay as an MCP tool server
assay mcp-server --port 3001 --policy policies/
```

The agent can call `assay_check_args` before executing:

```json
{
  "tool": "assay_check_args",
  "arguments": {
    "target_tool": "apply_discount",
    "args": { "percent": 50 }
  }
}
```

Response:
```json
{
  "allowed": false,
  "violations": [{"field": "percent", "constraint": "max: 30"}],
  "suggested_fix": {"percent": 30}
}
```

---

## Documentation

üìö **Full documentation:** [docs.assay.dev](https://docs.assay.dev)

- [Getting Started](https://docs.assay.dev/getting-started/)
- [Configuration Guide](https://docs.assay.dev/config/)
- [MCP Integration](https://docs.assay.dev/mcp/)
- [CLI Reference](https://docs.assay.dev/cli/)
- [Metrics Reference](https://docs.assay.dev/metrics/)

---

## Architecture

Assay is a Rust workspace with four crates:

| Crate | Role |
|-------|------|
| `assay-core` | Trace ingestion, replay engine, cache, storage |
| `assay-cli` | CLI interface, commands, formatting |
| `assay-metrics` | Pure validation functions (`args_valid`, etc.) |
| `assay-mcp-server` | MCP server for agent self-correction |

```
assay/
‚îú‚îÄ‚îÄ crates/
‚îÇ   ‚îú‚îÄ‚îÄ assay-core/
‚îÇ   ‚îú‚îÄ‚îÄ assay-cli/
‚îÇ   ‚îú‚îÄ‚îÄ assay-metrics/
‚îÇ   ‚îî‚îÄ‚îÄ assay-mcp-server/
‚îú‚îÄ‚îÄ docs/
‚îî‚îÄ‚îÄ examples/
```

---

## Contributing

We welcome contributions! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

```bash
# Clone
git clone https://github.com/Rul1an/assay.git
cd assay

# Build
cargo build

# Test
cargo test

# Run locally
cargo run -- run --config examples/mcp-eval.yaml
```

---

## License

MIT License. See [LICENSE](LICENSE).

---

## Why "Assay"?

> *In metallurgy, an **assay** determines the purity of precious metals.*
>
> *In software, Assay determines the quality of your AI.*

---

<p align="center">
  <sub>Built with ‚ù§Ô∏è for developers who are tired of flaky AI tests.</sub>
</p>
